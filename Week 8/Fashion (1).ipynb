{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OXD-a7q476I"
      },
      "source": [
        "# Image Classification by MLP - Fashion MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vu46JqyI476K"
      },
      "source": [
        "In this exercise, we will try to use a neural network on a simple classification task: classifying images of clothes into 10 classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRmZQVyH476K"
      },
      "source": [
        "We will first download the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5S6otQN476K",
        "outputId": "ae201986-24a9-4a4f-9f60-11f4c66ea83a",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 1s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (10000, 28, 28))"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "#TODO: load dataset\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "#TODO: Resample the dataset if needed\n",
        "# X_train = X_train[:10000]\n",
        "# y_train = y_train[:10000]\n",
        "# X_test = X_test[:2000]\n",
        "# y_test = y_test[:2000]\n",
        "\n",
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z__d-rdLoxVY",
        "outputId": "3dcdc584-5ab3-443a-f664-9558cc33e740"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.12.0-cp39-cp39-macosx_10_15_x86_64.whl (230.1 MB)\n",
            "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.6/230.1 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:14\u001b[0m"
          ]
        }
      ],
      "source": [
        "pip install tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2ZWOQ0n476L"
      },
      "source": [
        "This dataset contains 10 classes:\n",
        "* 0:\tT-shirt/top\n",
        "* 1:\tTrouser\n",
        "* 2:\tPullover\n",
        "* 3:\tDress\n",
        "* 4:\tCoat\n",
        "* 5:\tSandal\n",
        "* 6:\tShirt\n",
        "* 7:\tSneaker\n",
        "* 8:\tBag\n",
        "* 9:\tAnkle boot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpyM2qrx476L"
      },
      "source": [
        "Now begin by exploring the data. Try to display some images with the associated label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "bo9vZt8x476M",
        "outputId": "c16d2cd5-af3d-4444-ff10-6d5d1033fae5",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# TODO: Explore the data, display some input images\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "label_class = ['top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
        "\n",
        "# np.random.seed(0)\n",
        "idx = np.random.randint(X_train.shape[0])\n",
        "\n",
        "\n",
        "plt.imshow(X_train[idx], cmap='gray_r')\n",
        "plt.title(label_class[y_train[idx]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntujxVYk476M"
      },
      "source": [
        "**Before going further**: what methods could you use to perform such a classification task?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oy2xy7HE476M"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gf1CJfc9476M"
      },
      "source": [
        "The first method you will try is using neural networks. First step is the data preparation: data rescaling, label preparation.\n",
        "\n",
        "Hint: you can use the Keras function `to_categorical`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69gKAXvS476M",
        "outputId": "d0ece2fd-0805-4ba9-fcb7-69585aebbd5f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# TODO: Make the data preparation\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_cat = to_categorical(y_train, num_classes=10)\n",
        "y_test_cat = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "X_train_norm = X_train/255.\n",
        "X_test_norm = X_test/255.\n",
        "\n",
        "# TODO: reshape the image data (2D array) into input 1D array for a neural network\n",
        "X_train_norm = X_train_norm.reshape(X_train_norm.shape[0], np.prod(X_train_norm.shape[1:]))\n",
        "X_test_norm = X_test_norm.reshape(X_test_norm.shape[0], np.prod(X_test_norm.shape[1:]))\n",
        "\n",
        "X_train_norm.shape, y_train_cat.shape\n",
        "y_train_cat[234]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-FkKMZB476M"
      },
      "source": [
        "Next step: model building with Keras. Build your neural network architecture. At first, I would recommend a light architecture: no more than 2 hidden layers, with about 10 units per layer. Put that model into a function, so that you can reuse it later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtckGWxc476M",
        "outputId": "2d326dd3-0454-4c20-95e7-f8459eaf6b58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 30)                23550     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 40)                1240      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                410       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,200\n",
            "Trainable params: 25,200\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# TODO: Build your model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "def my_model(input_dim):\n",
        "    # Create the Sequential object\n",
        "    model = Sequential()\n",
        "\n",
        "    # Add 2 dense layers with 10 neurons each using sigmoid or relu activation\n",
        "    model.add(Dense(30, input_dim=input_dim, activation ='sigmoid'))\n",
        "    model.add(Dense(40, activation='sigmoid'))\n",
        "    \n",
        "    # Add the output layer with one unit: the predicted result\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    \n",
        "    return model\n",
        "\n",
        "my_model(X_train_norm.shape[1]).summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zh2yw1Rh476M"
      },
      "source": [
        "Now compile and fit your model on your training data. Since this is a multiclass classification, the loss is not `binary_crossentropy` anymore, but `categorical_crossentropy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bZt9maF476N",
        "outputId": "52618bfb-85c7-4350-f22e-a2fb80aed8f4",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "469/469 [==============================] - 7s 4ms/step - loss: 1.3043 - accuracy: 0.6133\n",
            "Epoch 2/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.6571 - accuracy: 0.7832\n",
            "Epoch 3/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4876 - accuracy: 0.8363\n",
            "Epoch 4/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.4252 - accuracy: 0.8513\n",
            "Epoch 5/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3948 - accuracy: 0.8607\n",
            "Epoch 6/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3743 - accuracy: 0.8671\n",
            "Epoch 7/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3593 - accuracy: 0.8715\n",
            "Epoch 8/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3479 - accuracy: 0.8758\n",
            "Epoch 9/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3392 - accuracy: 0.8787\n",
            "Epoch 10/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3318 - accuracy: 0.8818\n",
            "Epoch 11/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3231 - accuracy: 0.8850\n",
            "Epoch 12/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3181 - accuracy: 0.8855\n",
            "Epoch 13/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3123 - accuracy: 0.8874\n",
            "Epoch 14/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3073 - accuracy: 0.8884\n",
            "Epoch 15/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3024 - accuracy: 0.8901\n",
            "Epoch 16/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2992 - accuracy: 0.8920\n",
            "Epoch 17/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2946 - accuracy: 0.8940\n",
            "Epoch 18/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2919 - accuracy: 0.8932\n",
            "Epoch 19/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.2875 - accuracy: 0.8955\n",
            "Epoch 20/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.2839 - accuracy: 0.8976\n",
            "Epoch 21/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2813 - accuracy: 0.8975\n",
            "Epoch 22/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2777 - accuracy: 0.8982\n",
            "Epoch 23/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2752 - accuracy: 0.8993\n",
            "Epoch 24/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2722 - accuracy: 0.9008\n",
            "Epoch 25/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2689 - accuracy: 0.9022\n",
            "Epoch 26/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2679 - accuracy: 0.9029\n",
            "Epoch 27/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2647 - accuracy: 0.9035\n",
            "Epoch 28/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2620 - accuracy: 0.9039\n",
            "Epoch 29/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2594 - accuracy: 0.9051\n",
            "Epoch 30/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2574 - accuracy: 0.9063\n",
            "Epoch 31/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2537 - accuracy: 0.9076\n",
            "Epoch 32/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2525 - accuracy: 0.9080\n",
            "Epoch 33/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2512 - accuracy: 0.9088\n",
            "Epoch 34/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2489 - accuracy: 0.9098\n",
            "Epoch 35/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2466 - accuracy: 0.9098\n",
            "Epoch 36/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2434 - accuracy: 0.9113\n",
            "Epoch 37/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2434 - accuracy: 0.9110\n",
            "Epoch 38/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2409 - accuracy: 0.9119\n",
            "Epoch 39/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2381 - accuracy: 0.9126\n",
            "Epoch 40/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2363 - accuracy: 0.9133\n",
            "Epoch 41/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2355 - accuracy: 0.9143\n",
            "Epoch 42/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2327 - accuracy: 0.9160\n",
            "Epoch 43/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2316 - accuracy: 0.9155\n",
            "Epoch 44/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2290 - accuracy: 0.9166\n",
            "Epoch 45/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2275 - accuracy: 0.9173\n",
            "Epoch 46/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2262 - accuracy: 0.9180\n",
            "Epoch 47/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2253 - accuracy: 0.9181\n",
            "Epoch 48/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2225 - accuracy: 0.9191\n",
            "Epoch 49/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2223 - accuracy: 0.9185\n",
            "Epoch 50/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2210 - accuracy: 0.9194\n",
            "Epoch 51/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2183 - accuracy: 0.9213\n",
            "Epoch 52/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2176 - accuracy: 0.9211\n",
            "Epoch 53/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2152 - accuracy: 0.9218\n",
            "Epoch 54/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2143 - accuracy: 0.9224\n",
            "Epoch 55/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2121 - accuracy: 0.9227\n",
            "Epoch 56/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2117 - accuracy: 0.9226\n",
            "Epoch 57/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2093 - accuracy: 0.9233\n",
            "Epoch 58/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2084 - accuracy: 0.9244\n",
            "Epoch 59/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2082 - accuracy: 0.9242\n",
            "Epoch 60/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2060 - accuracy: 0.9248\n",
            "Epoch 61/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2057 - accuracy: 0.9252\n",
            "Epoch 62/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2037 - accuracy: 0.9259\n",
            "Epoch 63/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2024 - accuracy: 0.9268\n",
            "Epoch 64/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2018 - accuracy: 0.9265\n",
            "Epoch 65/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2004 - accuracy: 0.9272\n",
            "Epoch 66/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1993 - accuracy: 0.9273\n",
            "Epoch 67/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1985 - accuracy: 0.9273\n",
            "Epoch 68/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1964 - accuracy: 0.9285\n",
            "Epoch 69/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1954 - accuracy: 0.9288\n",
            "Epoch 70/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1955 - accuracy: 0.9298\n",
            "Epoch 71/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1953 - accuracy: 0.9296\n",
            "Epoch 72/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1939 - accuracy: 0.9297\n",
            "Epoch 73/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1917 - accuracy: 0.9308\n",
            "Epoch 74/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1905 - accuracy: 0.9314\n",
            "Epoch 75/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1895 - accuracy: 0.9318\n",
            "Epoch 76/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1887 - accuracy: 0.9317\n",
            "Epoch 77/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1875 - accuracy: 0.9322\n",
            "Epoch 78/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1870 - accuracy: 0.9315\n",
            "Epoch 79/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1850 - accuracy: 0.9334\n",
            "Epoch 80/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1842 - accuracy: 0.9337\n",
            "Epoch 81/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1837 - accuracy: 0.9337\n",
            "Epoch 82/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1814 - accuracy: 0.9344\n",
            "Epoch 83/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1814 - accuracy: 0.9343\n",
            "Epoch 84/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1805 - accuracy: 0.9343\n",
            "Epoch 85/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1809 - accuracy: 0.9349\n",
            "Epoch 86/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1789 - accuracy: 0.9350\n",
            "Epoch 87/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1783 - accuracy: 0.9353\n",
            "Epoch 88/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1775 - accuracy: 0.9359\n",
            "Epoch 89/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1757 - accuracy: 0.9365\n",
            "Epoch 90/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1768 - accuracy: 0.9360\n",
            "Epoch 91/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1743 - accuracy: 0.9373\n",
            "Epoch 92/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1750 - accuracy: 0.9371\n",
            "Epoch 93/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1735 - accuracy: 0.9368\n",
            "Epoch 94/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1723 - accuracy: 0.9379\n",
            "Epoch 95/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1716 - accuracy: 0.9376\n",
            "Epoch 96/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1699 - accuracy: 0.9388\n",
            "Epoch 97/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1697 - accuracy: 0.9391\n",
            "Epoch 98/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1691 - accuracy: 0.9385\n",
            "Epoch 99/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1681 - accuracy: 0.9394\n",
            "Epoch 100/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1676 - accuracy: 0.9397\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb3f81dbd00>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "#https://stackoverflow.com/questions/53014306/error-15-initializing-libiomp5-dylib-but-found-libiomp5-dylib-already-initial\n",
        "# os.environ['KMP_DUPLICATE_LIB_OK']='True' \n",
        "\n",
        "# TODO: Compile and fit your model\n",
        "model = my_model(input_dim=X_train_norm.shape[1])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train_norm, y_train_cat, epochs=100, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFVoRuHT476N"
      },
      "source": [
        "Once your model has been trained, compute the accuracy (and other metrics if you want) on the train and test dataset.\n",
        "\n",
        "Be careful, Keras returns softmax output (so an array of 10 values between 0 and 1, for which the sum is equal to 1). To compute correctly the accuracy, you have to convert that array into a categorical array with zeros and a 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgq3i-xX476N",
        "outputId": "e7964458-fd7b-49cb-8249-72b3bd25ea5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy on train with NN: 0.9431666731834412\n",
            "accuracy on test with NN: 0.8723999857902527\n"
          ]
        }
      ],
      "source": [
        "# TODO: Compute the accuracy of your model\n",
        "print('accuracy on train with NN:', model.evaluate(X_train_norm, y_train_cat, verbose=0, batch_size=512)[1])\n",
        "print('accuracy on test with NN:', model.evaluate(X_test_norm, y_test_cat, verbose=0, batch_size=512)[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJ8ht3bB476N"
      },
      "source": [
        "What do you think of those results? Can you improve it by changing the number of layers? Of units per layer? The number of epochs? The activation functions?\n",
        "\n",
        "You should try!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iW75BjBT476N"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeeZp763476N"
      },
      "source": [
        "In order to compare your results with more traditional machine learning methods, you will do this work with another method: a PCA followed by a classification model (of your choice). Of course, you can perform hyperparameter optimization using a gridsearch on that model!\n",
        "\n",
        "Fit your model and display the performances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nvj_lsR2476N"
      },
      "outputs": [],
      "source": [
        "# TODO: Redo the classification with PCA and classification model\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=0.9)\n",
        "\n",
        "pca.fit(X_train_norm)\n",
        "X_train_pca = pca.transform(X_train_norm)\n",
        "X_test_pca = pca.transform(X_test_norm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "r_hJI1En476O",
        "outputId": "eb7605a6-6bf8-430d-9993-f2bb54b509b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score with RF on train 1.0\n",
            "score with RF on test 0.8608\n"
          ]
        }
      ],
      "source": [
        "# TODO: use any classifier you want\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "rf.fit(X_train_pca, y_train)\n",
        "\n",
        "print('score with RF on train', rf.score(X_train_pca, y_train))\n",
        "print('score with RF on test', rf.score(X_test_pca, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5xHoCZ_476O"
      },
      "source": [
        "Are the performances different? Can you explain why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1Ddj1S2476O"
      },
      "source": [
        "If you still have time, you could try to use scikit-learn's `Pipeline` to perform the hyperparameter optimization jointly on the PCA and the classification model. This might improve your performances."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Create a pipeline\n",
        "pipe = make_pipeline((RandomForestClassifier()))\n",
        "# Create dictionary with candidate learning algorithms and their hyperparameters\n",
        "grid_param = [\n",
        "{\"randomforestclassifier\": [RandomForestClassifier()],\n",
        "\"randomforestclassifier__n_estimators\": [10, 100, 1000],\n",
        "\"randomforestclassifier__max_depth\":[5,8,15,25,30,None],\n",
        "\"randomforestclassifier__min_samples_leaf\":[1,2,5,10,15,100],\n",
        "\"randomforestclassifier__max_leaf_nodes\": [2, 5,10]}]\n",
        "# create a gridsearch of the pipeline, the fit the best model\n",
        "gridsearch = GridSearchCV(pipe, grid_param, cv=5, verbose=0,n_jobs=-1) # Fit grid search\n",
        "best_model = gridsearch.fit(X_train,y_train)\n",
        "best_model.score(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "WUsqjijUstMY",
        "outputId": "a53d2757-69a9-4f47-802e-a9e7cfad4392"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-ee5ea90e7ef3>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# create a gridsearch of the pipeline, the fit the best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mgridsearch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Fit grid search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgridsearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    565\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    451\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}