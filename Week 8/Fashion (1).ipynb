{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3OXD-a7q476I"
   },
   "source": [
    "# Image Classification by MLP - Fashion MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vu46JqyI476K"
   },
   "source": [
    "In this exercise, we will try to use a neural network on a simple classification task: classifying images of clothes into 10 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QRmZQVyH476K"
   },
   "source": [
    "We will first download the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r5S6otQN476K",
    "outputId": "f1b6db5e-7d76-4158-f5ba-1baa0e4f02a0",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2p/86dk0tk52cj_yh7fgx4gr6y00000gn/T/ipykernel_26007/1430780892.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfashion_mnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#TODO: load dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfashion_mnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "#TODO: load dataset\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "#TODO: Resample the dataset if needed\n",
    "X_train = X_train[:10000]\n",
    "y_train = y_train[:10000]\n",
    "X_test = X_test[:2000]\n",
    "y_test = y_test[:2000]\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.12.0-cp39-cp39-macosx_10_15_x86_64.whl (230.1 MB)\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.6/230.1 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:14\u001b[0m"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s2ZWOQ0n476L"
   },
   "source": [
    "This dataset contains 10 classes:\n",
    "* 0:\tT-shirt/top\n",
    "* 1:\tTrouser\n",
    "* 2:\tPullover\n",
    "* 3:\tDress\n",
    "* 4:\tCoat\n",
    "* 5:\tSandal\n",
    "* 6:\tShirt\n",
    "* 7:\tSneaker\n",
    "* 8:\tBag\n",
    "* 9:\tAnkle boot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZpyM2qrx476L"
   },
   "source": [
    "Now begin by exploring the data. Try to display some images with the associated label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "bo9vZt8x476M",
    "outputId": "3102649f-3b2a-47d5-f205-53f89a36f5f1",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Explore the data, display some input images\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "label_class = ['top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
    "\n",
    "# np.random.seed(0)\n",
    "idx = np.random.randint(X_train.shape[0])\n",
    "\n",
    "\n",
    "plt.imshow(X_train[idx], cmap='gray_r')\n",
    "plt.title(label_class[y_train[idx]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ntujxVYk476M"
   },
   "source": [
    "**Before going further**: what methods could you use to perform such a classification task?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oy2xy7HE476M"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gf1CJfc9476M"
   },
   "source": [
    "The first method you will try is using neural networks. First step is the data preparation: data rescaling, label preparation.\n",
    "\n",
    "Hint: you can use the Keras function `to_categorical`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "id": "69gKAXvS476M",
    "outputId": "81972aca-9be5-4291-87eb-4f3fdf772fcd"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-55ee514392f8>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# TODO: reshape the image data (2D array) into input 1D array for a neural network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mX_train_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mX_test_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mX_train_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_cat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 7840000 into shape (2000,784)"
     ]
    }
   ],
   "source": [
    "# TODO: Make the data preparation\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train_cat = to_categorical(y_train, num_classes=10)\n",
    "y_test_cat = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "X_train_norm = X_train/255.\n",
    "X_test_norm = X_test/255.\n",
    "\n",
    "# TODO: reshape the image data (2D array) into input 1D array for a neural network\n",
    "X_train_norm = X_train_norm.reshape(X_train_norm.shape[0], np.prod(X_train_norm.shape[1:]))\n",
    "X_test_norm = X_train_norm.reshape(X_test_norm.shape[0], np.prod(X_test_norm.shape[1:]))\n",
    "\n",
    "X_train_norm.shape, y_train_cat.shape\n",
    "y_train_cat[234]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-FkKMZB476M"
   },
   "source": [
    "Next step: model building with Keras. Build your neural network architecture. At first, I would recommend a light architecture: no more than 2 hidden layers, with about 10 units per layer. Put that model into a function, so that you can reuse it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vtckGWxc476M",
    "outputId": "44d2618d-bc8f-4a42-9da8-2a86d2e3ffe0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 30)                23550     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 40)                1240      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                410       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,200\n",
      "Trainable params: 25,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# TODO: Build your model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "def my_model(input_dim):\n",
    "    # Create the Sequential object\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add 2 dense layers with 10 neurons each using sigmoid or relu activation\n",
    "    model.add(Dense(30, input_dim=input_dim, activation ='sigmoid'))\n",
    "    model.add(Dense(40, activation='sigmoid'))\n",
    "    \n",
    "    # Add the output layer with one unit: the predicted result\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "my_model(X_train_norm.shape[1]).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zh2yw1Rh476M"
   },
   "source": [
    "Now compile and fit your model on your training data. Since this is a multiclass classification, the loss is not `binary_crossentropy` anymore, but `categorical_crossentropy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3bZt9maF476N",
    "outputId": "57267564-b7c8-4167-dfa9-8c7ce42a0ade",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "79/79 [==============================] - 1s 3ms/step - loss: 2.1099 - accuracy: 0.3484\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.6087 - accuracy: 0.5915\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.2487 - accuracy: 0.6693\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.0242 - accuracy: 0.7074\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.8787 - accuracy: 0.7471\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.7759 - accuracy: 0.7641\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.7025 - accuracy: 0.7777\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.6464 - accuracy: 0.7912\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.6036 - accuracy: 0.8057\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.5674 - accuracy: 0.8171\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.5361 - accuracy: 0.8229\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.8273\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.4885 - accuracy: 0.8370\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.8431\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.4521 - accuracy: 0.8478\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.8514\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.4257 - accuracy: 0.8550\n",
      "Epoch 18/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4145 - accuracy: 0.8573\n",
      "Epoch 19/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4032 - accuracy: 0.8612\n",
      "Epoch 20/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.3922 - accuracy: 0.8644\n",
      "Epoch 21/100\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.3830 - accuracy: 0.8671\n",
      "Epoch 22/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3759 - accuracy: 0.8714\n",
      "Epoch 23/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3679 - accuracy: 0.8732\n",
      "Epoch 24/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3601 - accuracy: 0.8743\n",
      "Epoch 25/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.3560 - accuracy: 0.8745\n",
      "Epoch 26/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.3474 - accuracy: 0.8790\n",
      "Epoch 27/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.3411 - accuracy: 0.8788\n",
      "Epoch 28/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.3377 - accuracy: 0.8816\n",
      "Epoch 29/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.3317 - accuracy: 0.8837\n",
      "Epoch 30/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.3259 - accuracy: 0.8846\n",
      "Epoch 31/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.3217 - accuracy: 0.8886\n",
      "Epoch 32/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.3157 - accuracy: 0.8914\n",
      "Epoch 33/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.3095 - accuracy: 0.8929\n",
      "Epoch 34/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.3040 - accuracy: 0.8915\n",
      "Epoch 35/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.3053 - accuracy: 0.8940\n",
      "Epoch 36/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.2978 - accuracy: 0.8970\n",
      "Epoch 37/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.2956 - accuracy: 0.8974\n",
      "Epoch 38/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.2930 - accuracy: 0.8964\n",
      "Epoch 39/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2867 - accuracy: 0.9006\n",
      "Epoch 40/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2809 - accuracy: 0.9023\n",
      "Epoch 41/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2779 - accuracy: 0.9058\n",
      "Epoch 42/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2740 - accuracy: 0.9040\n",
      "Epoch 43/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2730 - accuracy: 0.9051\n",
      "Epoch 44/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.2688 - accuracy: 0.9079\n",
      "Epoch 45/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2650 - accuracy: 0.9077\n",
      "Epoch 46/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2617 - accuracy: 0.9091\n",
      "Epoch 47/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2607 - accuracy: 0.9094\n",
      "Epoch 48/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2548 - accuracy: 0.9120\n",
      "Epoch 49/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2515 - accuracy: 0.9133\n",
      "Epoch 50/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.9147\n",
      "Epoch 51/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2461 - accuracy: 0.9173\n",
      "Epoch 52/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2441 - accuracy: 0.9153\n",
      "Epoch 53/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2408 - accuracy: 0.9185\n",
      "Epoch 54/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2380 - accuracy: 0.9188\n",
      "Epoch 55/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2357 - accuracy: 0.9193\n",
      "Epoch 56/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.2310 - accuracy: 0.9222\n",
      "Epoch 57/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2326 - accuracy: 0.9193\n",
      "Epoch 58/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2265 - accuracy: 0.9225\n",
      "Epoch 59/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2246 - accuracy: 0.9229\n",
      "Epoch 60/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2220 - accuracy: 0.9245\n",
      "Epoch 61/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2200 - accuracy: 0.9249\n",
      "Epoch 62/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.2153 - accuracy: 0.9280\n",
      "Epoch 63/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2140 - accuracy: 0.9280\n",
      "Epoch 64/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2133 - accuracy: 0.9304\n",
      "Epoch 65/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2087 - accuracy: 0.9305\n",
      "Epoch 66/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2058 - accuracy: 0.9330\n",
      "Epoch 67/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2014 - accuracy: 0.9324\n",
      "Epoch 68/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2025 - accuracy: 0.9309\n",
      "Epoch 69/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1995 - accuracy: 0.9332\n",
      "Epoch 70/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1993 - accuracy: 0.9334\n",
      "Epoch 71/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1942 - accuracy: 0.9357\n",
      "Epoch 72/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1917 - accuracy: 0.9365\n",
      "Epoch 73/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1898 - accuracy: 0.9390\n",
      "Epoch 74/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.1906 - accuracy: 0.9379\n",
      "Epoch 75/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1848 - accuracy: 0.9392\n",
      "Epoch 76/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.1870 - accuracy: 0.9390\n",
      "Epoch 77/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.1801 - accuracy: 0.9425\n",
      "Epoch 78/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1836 - accuracy: 0.9388\n",
      "Epoch 79/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1793 - accuracy: 0.9421\n",
      "Epoch 80/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.1743 - accuracy: 0.9444\n",
      "Epoch 81/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1739 - accuracy: 0.9446\n",
      "Epoch 82/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.1750 - accuracy: 0.9430\n",
      "Epoch 83/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.1694 - accuracy: 0.9453\n",
      "Epoch 84/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.1700 - accuracy: 0.9482\n",
      "Epoch 85/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.1655 - accuracy: 0.9479\n",
      "Epoch 86/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.1643 - accuracy: 0.9469\n",
      "Epoch 87/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.1651 - accuracy: 0.9470\n",
      "Epoch 88/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.1623 - accuracy: 0.9484\n",
      "Epoch 89/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.1612 - accuracy: 0.9488\n",
      "Epoch 90/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1575 - accuracy: 0.9508\n",
      "Epoch 91/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1544 - accuracy: 0.9498\n",
      "Epoch 92/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1527 - accuracy: 0.9538\n",
      "Epoch 93/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.1542 - accuracy: 0.9504\n",
      "Epoch 94/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1501 - accuracy: 0.9536\n",
      "Epoch 95/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1482 - accuracy: 0.9533\n",
      "Epoch 96/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1510 - accuracy: 0.9527\n",
      "Epoch 97/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.1428 - accuracy: 0.9564\n",
      "Epoch 98/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.1421 - accuracy: 0.9566\n",
      "Epoch 99/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1394 - accuracy: 0.9564\n",
      "Epoch 100/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.1420 - accuracy: 0.9564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6e71d058a0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#https://stackoverflow.com/questions/53014306/error-15-initializing-libiomp5-dylib-but-found-libiomp5-dylib-already-initial\n",
    "# os.environ['KMP_DUPLICATE_LIB_OK']='True' \n",
    "\n",
    "# TODO: Compile and fit your model\n",
    "model = my_model(input_dim=X_train_norm.shape[1])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_norm, y_train_cat, epochs=100, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFVoRuHT476N"
   },
   "source": [
    "Once your model has been trained, compute the accuracy (and other metrics if you want) on the train and test dataset.\n",
    "\n",
    "Be careful, Keras returns softmax output (so an array of 10 values between 0 and 1, for which the sum is equal to 1). To compute correctly the accuracy, you have to convert that array into a categorical array with zeros and a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 728
    },
    "id": "wgq3i-xX476N",
    "outputId": "6a717392-d2b0-49ef-b62f-66bc4977c80a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on train with NN: 0.9574000239372253\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-cf7b5280f3c8>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# TODO: Compute the accuracy of your model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy on train with NN:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy on test with NN:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__test_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1852, in test_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1836, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1824, in run_step  **\n        outputs = model.test_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1788, in test_step\n        y_pred = self(x, training=False)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/activations.py\", line 83, in softmax\n        if x.shape.rank > 1:\n\n    TypeError: Exception encountered when calling layer 'dense_5' (type Dense).\n    \n    '>' not supported between instances of 'NoneType' and 'int'\n    \n    Call arguments received by layer 'dense_5' (type Dense):\n      • inputs=tf.Tensor(shape=<unknown>, dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Compute the accuracy of your model\n",
    "print('accuracy on train with NN:', model.evaluate(X_train_norm, y_train_cat, verbose=0, batch_size=512)[1])\n",
    "print('accuracy on test with NN:', model.evaluate(X_test_norm, y_test_cat, verbose=0, batch_size=512)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJ8ht3bB476N"
   },
   "source": [
    "What do you think of those results? Can you improve it by changing the number of layers? Of units per layer? The number of epochs? The activation functions?\n",
    "\n",
    "You should try!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iW75BjBT476N"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BeeZp763476N"
   },
   "source": [
    "In order to compare your results with more traditional machine learning methods, you will do this work with another method: a PCA followed by a classification model (of your choice). Of course, you can perform hyperparameter optimization using a gridsearch on that model!\n",
    "\n",
    "Fit your model and display the performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 371
    },
    "id": "nvj_lsR2476N",
    "outputId": "438c6772-d16e-49ce-ae87-c15e94c026cd"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-984193317236>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mX_train_pca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mX_test_pca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    913\u001b[0m             )\n\u001b[1;32m    914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    916\u001b[0m                 \u001b[0;34m\"Found array with dim %d. %s expected <= 2.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m                 \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with dim 3. PCA expected <= 2."
     ]
    }
   ],
   "source": [
    "# TODO: Redo the classification with PCA and classification model\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.9)\n",
    "\n",
    "pca.fit(X_train_norm)\n",
    "X_train_pca = pca.transform(X_train_norm)\n",
    "X_test_pca = pca.transform(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r_hJI1En476O",
    "outputId": "1434c60b-f1a3-4b91-ad1e-ed229aff6fa1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score with RF on train 1.0\n",
      "score with RF on train 0.836\n"
     ]
    }
   ],
   "source": [
    "# TODO: use any classifier you want\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf.fit(X_train_pca, y_train)\n",
    "\n",
    "print('score with RF on train', rf.score(X_train_pca, y_train))\n",
    "print('score with RF on test', rf.score(X_test_pca, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y5xHoCZ_476O"
   },
   "source": [
    "Are the performances different? Can you explain why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L1Ddj1S2476O"
   },
   "source": [
    "If you still have time, you could try to use scikit-learn's `Pipeline` to perform the hyperparameter optimization jointly on the PCA and the classification model. This might improve your performances."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
