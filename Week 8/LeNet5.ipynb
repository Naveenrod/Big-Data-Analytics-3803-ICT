{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Naveenrod/Big-Data-Analytics-3803-ICT/blob/main/Week%208/LeNet5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDbJWoO1yO8e"
      },
      "source": [
        "# Image Classification with CNN - LeNet5 architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzQxqD6HyO8i"
      },
      "source": [
        "In this exercise, we will apply the LeNet5 algorithm to the Fashion MNIST dataset and improve your performances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFyVotRvyO8j"
      },
      "source": [
        "We will first download the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTHLyL1fyO8j",
        "outputId": "18222b9e-90c5-40d1-aa61-446fe4c95057",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# TODO: Load the dataset\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# # # If your computer is slow, try to use a subset of data, e.g.\n",
        "# X_train = X_train[:10000]\n",
        "# y_train = y_train[:10000]\n",
        "# X_test = X_test[:2000]\n",
        "# y_test = y_test[:2000]\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8ShXIANyO8l"
      },
      "source": [
        "As you already know, this dataset contains 10 classes:\n",
        "* 0:\tT-shirt/top\n",
        "* 1:\tTrouser\n",
        "* 2:\tPullover\n",
        "* 3:\tDress\n",
        "* 4:\tCoat\n",
        "* 5:\tSandal\n",
        "* 6:\tShirt\n",
        "* 7:\tSneaker\n",
        "* 8:\tBag\n",
        "* 9:\tAnkle boot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BvNG0PbyO8l"
      },
      "source": [
        "You can have a look at some images if needed, even if you already know them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "lnjqgv-GyO8m",
        "outputId": "ab0fced9-6123-4f3d-8974-7372a88bee8e",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# TODO: Explore the data, display some input images\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "label_class = ['top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
        "\n",
        "idx = np.random.randint(X_train.shape[0])\n",
        "\n",
        "plt.imshow(X_train[idx], cmap='gray_r')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdYH6XW1yO8n"
      },
      "source": [
        "Make the data preparation and preprocessing: scale and reshape the data, put the labels to the good shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fjv8XMPByO8o",
        "outputId": "6dd6a3da-737c-4664-9d85-8db2783a10f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# TODO: Make the data preparation\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_cat = to_categorical(y_train, num_classes=10)\n",
        "y_test_cat = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "X_train_norm = X_train/255\n",
        "X_test_norm = X_test/255\n",
        "\n",
        "\n",
        "X_train_norm = X_train_norm.reshape(X_train_norm.shape[0], 28, 28, 1)\n",
        "X_test_norm = X_test_norm.reshape(X_test_norm.shape[0], 28, 28, 1)\n",
        "\n",
        "X_train_norm.shape #Should be (60000, 28, 28, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9LKzxR9yO8o"
      },
      "source": [
        "Now build the LeNet5 architecture. You can reuse the one of the course, or try to build it by yourself.\n",
        "\n",
        "The architecture is the following:\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1WteTU2FPIVMkBKmMxGpFm5OjsX-szTbB\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GKyMFlL6yO8o"
      },
      "outputs": [],
      "source": [
        "# TODO: Build your model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import MaxPooling2D, Conv2D, Flatten, Dense\n",
        "\n",
        "\n",
        "def lenet5():\n",
        "    \n",
        "    model = Sequential()\n",
        "\n",
        "    # Layer C1\n",
        "    model.add(Conv2D(filters=6, name='C1', kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
        "    # Layer S2\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), name='S2'))\n",
        "    # Layer C3\n",
        "    model.add(Conv2D(filters=16, name='C3', kernel_size=(3, 3), activation='relu'))\n",
        "    # Layer S4\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), name='S4'))\n",
        "    # Before going into layer C5, we flatten our units\n",
        "    model.add(Flatten())\n",
        "    # Layer C5\n",
        "    model.add(Dense(units=84, activation = 'relu', name='C5'))\n",
        "    # Layer F6\n",
        "    model.add(Dense(units=84, activation = 'relu', name='F6'))\n",
        "    # Output layer\n",
        "    model.add(Dense(units=10, activation = 'softmax'))\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1qBEauqyO8p"
      },
      "source": [
        "Now compile and fit your model on your training data. Since this is a multiclass classification, the loss is not `binary_crossentropy` anymore, but `categorical_crossentropy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPL3aKnyyO8p",
        "outputId": "b5a32ebf-6b77-4bf1-b436-f4272b1d0454",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "30/30 [==============================] - 12s 29ms/step - loss: 1.6935 - accuracy: 0.4865 - val_loss: 0.9750 - val_accuracy: 0.6355\n",
            "Epoch 2/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.8051 - accuracy: 0.7021 - val_loss: 0.7299 - val_accuracy: 0.7342\n",
            "Epoch 3/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.6673 - accuracy: 0.7492 - val_loss: 0.6510 - val_accuracy: 0.7593\n",
            "Epoch 4/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.6055 - accuracy: 0.7699 - val_loss: 0.6171 - val_accuracy: 0.7712\n",
            "Epoch 5/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.5642 - accuracy: 0.7848 - val_loss: 0.5962 - val_accuracy: 0.7719\n",
            "Epoch 6/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.5353 - accuracy: 0.7959 - val_loss: 0.5386 - val_accuracy: 0.8008\n",
            "Epoch 7/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.5074 - accuracy: 0.8092 - val_loss: 0.5201 - val_accuracy: 0.8064\n",
            "Epoch 8/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.4834 - accuracy: 0.8193 - val_loss: 0.4943 - val_accuracy: 0.8204\n",
            "Epoch 9/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.4652 - accuracy: 0.8296 - val_loss: 0.4823 - val_accuracy: 0.8247\n",
            "Epoch 10/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.4479 - accuracy: 0.8372 - val_loss: 0.4712 - val_accuracy: 0.8293\n",
            "Epoch 11/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.4331 - accuracy: 0.8433 - val_loss: 0.4561 - val_accuracy: 0.8322\n",
            "Epoch 12/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.4219 - accuracy: 0.8477 - val_loss: 0.4425 - val_accuracy: 0.8412\n",
            "Epoch 13/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.4098 - accuracy: 0.8508 - val_loss: 0.4359 - val_accuracy: 0.8409\n",
            "Epoch 14/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3993 - accuracy: 0.8563 - val_loss: 0.4325 - val_accuracy: 0.8429\n",
            "Epoch 15/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3986 - accuracy: 0.8549 - val_loss: 0.4222 - val_accuracy: 0.8452\n",
            "Epoch 16/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3874 - accuracy: 0.8594 - val_loss: 0.4097 - val_accuracy: 0.8535\n",
            "Epoch 17/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3764 - accuracy: 0.8639 - val_loss: 0.4102 - val_accuracy: 0.8492\n",
            "Epoch 18/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3719 - accuracy: 0.8655 - val_loss: 0.4027 - val_accuracy: 0.8533\n",
            "Epoch 19/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3656 - accuracy: 0.8672 - val_loss: 0.3966 - val_accuracy: 0.8566\n",
            "Epoch 20/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.3575 - accuracy: 0.8703 - val_loss: 0.3875 - val_accuracy: 0.8621\n",
            "Epoch 21/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3549 - accuracy: 0.8711 - val_loss: 0.4187 - val_accuracy: 0.8452\n",
            "Epoch 22/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3570 - accuracy: 0.8687 - val_loss: 0.3831 - val_accuracy: 0.8617\n",
            "Epoch 23/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3460 - accuracy: 0.8740 - val_loss: 0.3755 - val_accuracy: 0.8642\n",
            "Epoch 24/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.3386 - accuracy: 0.8766 - val_loss: 0.3830 - val_accuracy: 0.8622\n",
            "Epoch 25/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.3400 - accuracy: 0.8752 - val_loss: 0.3764 - val_accuracy: 0.8640\n",
            "Epoch 26/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3321 - accuracy: 0.8792 - val_loss: 0.3818 - val_accuracy: 0.8617\n",
            "Epoch 27/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.3336 - accuracy: 0.8790 - val_loss: 0.3697 - val_accuracy: 0.8653\n",
            "Epoch 28/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3256 - accuracy: 0.8816 - val_loss: 0.3620 - val_accuracy: 0.8684\n",
            "Epoch 29/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.3238 - accuracy: 0.8819 - val_loss: 0.3583 - val_accuracy: 0.8695\n",
            "Epoch 30/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.3216 - accuracy: 0.8828 - val_loss: 0.3608 - val_accuracy: 0.8690\n",
            "Epoch 31/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.3170 - accuracy: 0.8842 - val_loss: 0.3612 - val_accuracy: 0.8688\n",
            "Epoch 32/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.3120 - accuracy: 0.8858 - val_loss: 0.3494 - val_accuracy: 0.8729\n",
            "Epoch 33/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3105 - accuracy: 0.8866 - val_loss: 0.3492 - val_accuracy: 0.8728\n",
            "Epoch 34/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.3076 - accuracy: 0.8874 - val_loss: 0.3536 - val_accuracy: 0.8717\n",
            "Epoch 35/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.3060 - accuracy: 0.8877 - val_loss: 0.3636 - val_accuracy: 0.8685\n",
            "Epoch 36/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.3020 - accuracy: 0.8895 - val_loss: 0.3451 - val_accuracy: 0.8741\n",
            "Epoch 37/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.3022 - accuracy: 0.8892 - val_loss: 0.3481 - val_accuracy: 0.8705\n",
            "Epoch 38/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2988 - accuracy: 0.8908 - val_loss: 0.3457 - val_accuracy: 0.8710\n",
            "Epoch 39/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2950 - accuracy: 0.8919 - val_loss: 0.3423 - val_accuracy: 0.8758\n",
            "Epoch 40/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.2941 - accuracy: 0.8925 - val_loss: 0.3422 - val_accuracy: 0.8757\n",
            "Epoch 41/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2912 - accuracy: 0.8934 - val_loss: 0.3387 - val_accuracy: 0.8755\n",
            "Epoch 42/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.2902 - accuracy: 0.8937 - val_loss: 0.3415 - val_accuracy: 0.8718\n",
            "Epoch 43/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2903 - accuracy: 0.8940 - val_loss: 0.3316 - val_accuracy: 0.8801\n",
            "Epoch 44/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2852 - accuracy: 0.8957 - val_loss: 0.3363 - val_accuracy: 0.8764\n",
            "Epoch 45/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.2824 - accuracy: 0.8974 - val_loss: 0.3352 - val_accuracy: 0.8743\n",
            "Epoch 46/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.2841 - accuracy: 0.8961 - val_loss: 0.3389 - val_accuracy: 0.8784\n",
            "Epoch 47/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2814 - accuracy: 0.8975 - val_loss: 0.3332 - val_accuracy: 0.8781\n",
            "Epoch 48/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.2780 - accuracy: 0.8981 - val_loss: 0.3319 - val_accuracy: 0.8760\n",
            "Epoch 49/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.2789 - accuracy: 0.8976 - val_loss: 0.3298 - val_accuracy: 0.8781\n",
            "Epoch 50/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2744 - accuracy: 0.8996 - val_loss: 0.3323 - val_accuracy: 0.8756\n",
            "Epoch 51/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2768 - accuracy: 0.8979 - val_loss: 0.3282 - val_accuracy: 0.8776\n",
            "Epoch 52/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2723 - accuracy: 0.9004 - val_loss: 0.3474 - val_accuracy: 0.8721\n",
            "Epoch 53/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2759 - accuracy: 0.8982 - val_loss: 0.3284 - val_accuracy: 0.8778\n",
            "Epoch 54/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2702 - accuracy: 0.9005 - val_loss: 0.3211 - val_accuracy: 0.8817\n",
            "Epoch 55/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2663 - accuracy: 0.9026 - val_loss: 0.3233 - val_accuracy: 0.8830\n",
            "Epoch 56/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2686 - accuracy: 0.9010 - val_loss: 0.3270 - val_accuracy: 0.8781\n",
            "Epoch 57/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2658 - accuracy: 0.9014 - val_loss: 0.3234 - val_accuracy: 0.8780\n",
            "Epoch 58/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2624 - accuracy: 0.9037 - val_loss: 0.3171 - val_accuracy: 0.8823\n",
            "Epoch 59/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2605 - accuracy: 0.9046 - val_loss: 0.3241 - val_accuracy: 0.8792\n",
            "Epoch 60/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.2652 - accuracy: 0.9024 - val_loss: 0.3164 - val_accuracy: 0.8841\n",
            "Epoch 61/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2596 - accuracy: 0.9043 - val_loss: 0.3163 - val_accuracy: 0.8839\n",
            "Epoch 62/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2580 - accuracy: 0.9038 - val_loss: 0.3285 - val_accuracy: 0.8786\n",
            "Epoch 63/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2582 - accuracy: 0.9043 - val_loss: 0.3147 - val_accuracy: 0.8824\n",
            "Epoch 64/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2531 - accuracy: 0.9074 - val_loss: 0.3186 - val_accuracy: 0.8840\n",
            "Epoch 65/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2517 - accuracy: 0.9076 - val_loss: 0.3182 - val_accuracy: 0.8828\n",
            "Epoch 66/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2546 - accuracy: 0.9063 - val_loss: 0.3206 - val_accuracy: 0.8809\n",
            "Epoch 67/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.2526 - accuracy: 0.9072 - val_loss: 0.3145 - val_accuracy: 0.8842\n",
            "Epoch 68/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.2501 - accuracy: 0.9082 - val_loss: 0.3178 - val_accuracy: 0.8819\n",
            "Epoch 69/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2498 - accuracy: 0.9077 - val_loss: 0.3133 - val_accuracy: 0.8853\n",
            "Epoch 70/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2453 - accuracy: 0.9095 - val_loss: 0.3211 - val_accuracy: 0.8822\n",
            "Epoch 71/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2451 - accuracy: 0.9093 - val_loss: 0.3148 - val_accuracy: 0.8839\n",
            "Epoch 72/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2453 - accuracy: 0.9100 - val_loss: 0.3201 - val_accuracy: 0.8877\n",
            "Epoch 73/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2434 - accuracy: 0.9104 - val_loss: 0.3124 - val_accuracy: 0.8866\n",
            "Epoch 74/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2435 - accuracy: 0.9096 - val_loss: 0.3161 - val_accuracy: 0.8853\n",
            "Epoch 75/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2419 - accuracy: 0.9102 - val_loss: 0.3156 - val_accuracy: 0.8824\n",
            "Epoch 76/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2427 - accuracy: 0.9098 - val_loss: 0.3127 - val_accuracy: 0.8839\n",
            "Epoch 77/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2422 - accuracy: 0.9108 - val_loss: 0.3147 - val_accuracy: 0.8844\n",
            "Epoch 78/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2401 - accuracy: 0.9115 - val_loss: 0.3235 - val_accuracy: 0.8810\n",
            "Epoch 79/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2461 - accuracy: 0.9082 - val_loss: 0.3099 - val_accuracy: 0.8863\n",
            "Epoch 80/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2342 - accuracy: 0.9139 - val_loss: 0.3134 - val_accuracy: 0.8849\n",
            "Epoch 81/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2349 - accuracy: 0.9128 - val_loss: 0.3078 - val_accuracy: 0.8878\n",
            "Epoch 82/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2329 - accuracy: 0.9142 - val_loss: 0.3048 - val_accuracy: 0.8897\n",
            "Epoch 83/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2319 - accuracy: 0.9144 - val_loss: 0.3172 - val_accuracy: 0.8853\n",
            "Epoch 84/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2323 - accuracy: 0.9143 - val_loss: 0.3114 - val_accuracy: 0.8862\n",
            "Epoch 85/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2332 - accuracy: 0.9137 - val_loss: 0.3153 - val_accuracy: 0.8850\n",
            "Epoch 86/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2348 - accuracy: 0.9137 - val_loss: 0.3112 - val_accuracy: 0.8868\n",
            "Epoch 87/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2319 - accuracy: 0.9141 - val_loss: 0.3044 - val_accuracy: 0.8878\n",
            "Epoch 88/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2282 - accuracy: 0.9169 - val_loss: 0.3054 - val_accuracy: 0.8904\n",
            "Epoch 89/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2285 - accuracy: 0.9162 - val_loss: 0.3025 - val_accuracy: 0.8904\n",
            "Epoch 90/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2233 - accuracy: 0.9180 - val_loss: 0.3192 - val_accuracy: 0.8831\n",
            "Epoch 91/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.2280 - accuracy: 0.9156 - val_loss: 0.3303 - val_accuracy: 0.8819\n",
            "Epoch 92/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2264 - accuracy: 0.9163 - val_loss: 0.3035 - val_accuracy: 0.8903\n",
            "Epoch 93/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2246 - accuracy: 0.9176 - val_loss: 0.3149 - val_accuracy: 0.8856\n",
            "Epoch 94/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.2207 - accuracy: 0.9188 - val_loss: 0.3053 - val_accuracy: 0.8897\n",
            "Epoch 95/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2196 - accuracy: 0.9196 - val_loss: 0.3109 - val_accuracy: 0.8906\n",
            "Epoch 96/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2187 - accuracy: 0.9199 - val_loss: 0.3211 - val_accuracy: 0.8838\n",
            "Epoch 97/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2224 - accuracy: 0.9180 - val_loss: 0.3077 - val_accuracy: 0.8909\n",
            "Epoch 98/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.2200 - accuracy: 0.9183 - val_loss: 0.3091 - val_accuracy: 0.8857\n",
            "Epoch 99/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.2168 - accuracy: 0.9205 - val_loss: 0.3128 - val_accuracy: 0.8876\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f52281cece0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from sklearn import metrics\n",
        "# TODO: Compile and fit your model\n",
        "import os\n",
        "\n",
        "# os.environ['KMP_DUPLICATE_LIB_OK']='True' #https://stackoverflow.com/questions/53014306/error-15-initializing-libiomp5-dylib-but-found-libiomp5-dylib-already-initial\n",
        "\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "model = lenet5()\n",
        "\n",
        "model.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define now our callbacks\n",
        "# callbacks = [EarlyStopping(monitor='val_loss', patience=10), TensorBoard(log_dir='./keras-logs', histogram_freq=0, write_graph=True, write_images=True)]\n",
        "callbacks = [EarlyStopping(monitor='val_loss', patience=10)]\n",
        "\n",
        "# Finally fit the model\n",
        "model.fit(x=X_train_norm, y=y_train_cat, validation_data=(X_test_norm, y_test_cat), epochs=100, batch_size=2048, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf-SqjjOyO8q"
      },
      "source": [
        "Have a look at the tensorboard and see if it gives a deeper understanding of your model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2FTj7TSyO8q"
      },
      "source": [
        "Compute then the accuracy of your model. Is it better than a regular MLP used before?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPjJoMQZyO8q",
        "outputId": "d4ac39cd-191f-47f6-dbb4-50ba029ba683"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59/59 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 11ms/step\n",
            "accuracy on train with NN: 0.9180333333333334\n",
            "accuracy on test with NN: 0.8876\n"
          ]
        }
      ],
      "source": [
        "# TODO: Compute the accuracy of your model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "bs = 1024\n",
        "y_pred_train = to_categorical(model.predict(X_train_norm, batch_size=bs).argmax(axis=1), num_classes=10)\n",
        "y_pred_test = to_categorical(model.predict(X_test_norm, batch_size=bs).argmax(axis=1), num_classes=10)\n",
        "\n",
        "print('accuracy on train with NN:', accuracy_score(y_pred_train, y_train_cat))\n",
        "print('accuracy on test with NN:', accuracy_score(y_pred_test, y_test_cat))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vulsgHiyO8q"
      },
      "source": [
        "We will now add image augmentation to improve our results, especially we will try to reduce overfitting this way.\n",
        "\n",
        "To do so, you can use `ImageDataGenerator` from Keras that makes all the work for you (including rescaling), with the following parameter: \n",
        "* `horizontal_flip=True`\n",
        "\n",
        "For more info about how the `ImageDataGenerator` works, you can check out [this article](https://www.pyimagesearch.com/2019/07/08/keras-imagedatagenerator-and-data-augmentation/).\n",
        "\n",
        "Begin by creating an object `ImageDataGenerator` with this parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-19T11:58:37.442182Z",
          "start_time": "2020-08-19T11:58:37.438397Z"
        },
        "id": "pas-fMSIyO8q"
      },
      "outputs": [],
      "source": [
        "# TODO: Instantiate an ImageDataGenerator object\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(horizontal_flip=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7nCnu9syO8r"
      },
      "source": [
        "Finally, you can train your model using this generator, with the method `fit_generator` of your model and the method `flow` of your `ImageDataGenerator`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zt6wXa3IyO8r",
        "outputId": "5c321322-b2a7-460c-d53a-7260df20303c",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-5da9cbf7d7d8>:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(datagen.flow(X_train_norm, y_train_cat, batch_size=batch_size),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58/58 [==============================] - 3s 45ms/step - loss: 0.4408 - accuracy: 0.8575 - val_loss: 0.3353 - val_accuracy: 0.8810\n",
            "Epoch 2/100\n",
            "58/58 [==============================] - 3s 59ms/step - loss: 0.2971 - accuracy: 0.8923 - val_loss: 0.3178 - val_accuracy: 0.8856\n",
            "Epoch 3/100\n",
            "58/58 [==============================] - 4s 60ms/step - loss: 0.2815 - accuracy: 0.8971 - val_loss: 0.3133 - val_accuracy: 0.8861\n",
            "Epoch 4/100\n",
            "58/58 [==============================] - 2s 42ms/step - loss: 0.2748 - accuracy: 0.8985 - val_loss: 0.3081 - val_accuracy: 0.8892\n",
            "Epoch 5/100\n",
            "58/58 [==============================] - 3s 54ms/step - loss: 0.2690 - accuracy: 0.9019 - val_loss: 0.3048 - val_accuracy: 0.8890\n",
            "Epoch 6/100\n",
            "58/58 [==============================] - 2s 42ms/step - loss: 0.2675 - accuracy: 0.9018 - val_loss: 0.3150 - val_accuracy: 0.8874\n",
            "Epoch 7/100\n",
            "58/58 [==============================] - 4s 62ms/step - loss: 0.2614 - accuracy: 0.9042 - val_loss: 0.3038 - val_accuracy: 0.8901\n",
            "Epoch 8/100\n",
            "58/58 [==============================] - 3s 55ms/step - loss: 0.2569 - accuracy: 0.9044 - val_loss: 0.3086 - val_accuracy: 0.8897\n",
            "Epoch 9/100\n",
            "58/58 [==============================] - 3s 55ms/step - loss: 0.2559 - accuracy: 0.9053 - val_loss: 0.3015 - val_accuracy: 0.8885\n",
            "Epoch 10/100\n",
            "58/58 [==============================] - 3s 55ms/step - loss: 0.2537 - accuracy: 0.9058 - val_loss: 0.2994 - val_accuracy: 0.8941\n",
            "Epoch 11/100\n",
            "58/58 [==============================] - 5s 81ms/step - loss: 0.2492 - accuracy: 0.9076 - val_loss: 0.3124 - val_accuracy: 0.8863\n",
            "Epoch 12/100\n",
            "58/58 [==============================] - 4s 63ms/step - loss: 0.2483 - accuracy: 0.9087 - val_loss: 0.3041 - val_accuracy: 0.8908\n",
            "Epoch 13/100\n",
            "58/58 [==============================] - 5s 80ms/step - loss: 0.2435 - accuracy: 0.9102 - val_loss: 0.3004 - val_accuracy: 0.8930\n",
            "Epoch 14/100\n",
            "58/58 [==============================] - 5s 91ms/step - loss: 0.2425 - accuracy: 0.9106 - val_loss: 0.3036 - val_accuracy: 0.8913\n",
            "Epoch 15/100\n",
            "58/58 [==============================] - 3s 54ms/step - loss: 0.2420 - accuracy: 0.9110 - val_loss: 0.2966 - val_accuracy: 0.8927\n",
            "Epoch 16/100\n",
            "58/58 [==============================] - 4s 68ms/step - loss: 0.2429 - accuracy: 0.9100 - val_loss: 0.2949 - val_accuracy: 0.8947\n",
            "Epoch 17/100\n",
            "58/58 [==============================] - 3s 52ms/step - loss: 0.2391 - accuracy: 0.9119 - val_loss: 0.2950 - val_accuracy: 0.8924\n",
            "Epoch 18/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.2345 - accuracy: 0.9132 - val_loss: 0.3016 - val_accuracy: 0.8917\n",
            "Epoch 19/100\n",
            "58/58 [==============================] - 3s 54ms/step - loss: 0.2367 - accuracy: 0.9118 - val_loss: 0.2967 - val_accuracy: 0.8906\n",
            "Epoch 20/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.2368 - accuracy: 0.9117 - val_loss: 0.2919 - val_accuracy: 0.8977\n",
            "Epoch 21/100\n",
            "58/58 [==============================] - 2s 42ms/step - loss: 0.2299 - accuracy: 0.9147 - val_loss: 0.3024 - val_accuracy: 0.8929\n",
            "Epoch 22/100\n",
            "58/58 [==============================] - 2s 43ms/step - loss: 0.2310 - accuracy: 0.9145 - val_loss: 0.2945 - val_accuracy: 0.8962\n",
            "Epoch 23/100\n",
            "58/58 [==============================] - 3s 57ms/step - loss: 0.2289 - accuracy: 0.9146 - val_loss: 0.2996 - val_accuracy: 0.8945\n",
            "Epoch 24/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.2264 - accuracy: 0.9165 - val_loss: 0.3053 - val_accuracy: 0.8914\n",
            "Epoch 25/100\n",
            "58/58 [==============================] - 2s 41ms/step - loss: 0.2283 - accuracy: 0.9160 - val_loss: 0.2921 - val_accuracy: 0.8968\n",
            "Epoch 26/100\n",
            "58/58 [==============================] - 3s 54ms/step - loss: 0.2215 - accuracy: 0.9182 - val_loss: 0.3040 - val_accuracy: 0.8906\n",
            "Epoch 27/100\n",
            "58/58 [==============================] - 3s 54ms/step - loss: 0.2244 - accuracy: 0.9165 - val_loss: 0.2931 - val_accuracy: 0.8965\n",
            "Epoch 28/100\n",
            "58/58 [==============================] - 3s 43ms/step - loss: 0.2303 - accuracy: 0.9150 - val_loss: 0.3019 - val_accuracy: 0.8912\n",
            "Epoch 29/100\n",
            "58/58 [==============================] - 3s 51ms/step - loss: 0.2241 - accuracy: 0.9162 - val_loss: 0.2989 - val_accuracy: 0.8908\n",
            "Epoch 30/100\n",
            "58/58 [==============================] - 3s 54ms/step - loss: 0.2176 - accuracy: 0.9186 - val_loss: 0.2999 - val_accuracy: 0.8934\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f519429dc00>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# TODO: train your model\n",
        "batch_size = 1024\n",
        "model.fit_generator(datagen.flow(X_train_norm, y_train_cat, batch_size=batch_size),\n",
        "                    validation_data=(X_test_norm, y_test_cat), callbacks=callbacks,\n",
        "                    steps_per_epoch=len(X_train_norm) / batch_size, epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuzFke8pyO8r"
      },
      "source": [
        "Recompute the accuracy of your model, does it improve your performances with data augmentation?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "jsTm86tuyO8r",
        "outputId": "486e3a8a-0481-4fbb-9381-79a3c66ca41f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-fa2592613ba5>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my_pred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy on train with NN:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy on test with NN:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multilabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     96\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[1;32m     97\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of unknown and multilabel-indicator targets"
          ]
        }
      ],
      "source": [
        "# TODO: Compute the accuracy of your model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "batch_size=1024\n",
        "y_pred_train = to_categorical(X_train_norm, num_classes=10)\n",
        "y_pred_test = to_categorical(X_test_norm, num_classes=10)\n",
        "\n",
        "print('accuracy on train with NN:', accuracy_score(y_pred_train, y_train_cat))\n",
        "print('accuracy on test with NN:', accuracy_score(y_pred_test, y_test_cat))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOzkdGf7yO8s"
      },
      "source": [
        "You can now try to improve even more your results. For example, add more parameters to your `ImageDataGenerator`, play with some hyperparameters, and so on..."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "01-LeNet5-solution.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}